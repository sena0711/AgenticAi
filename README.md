# AgenticAi 
About Agentic AI
2025 04 09 AWS 관련하여 정리
"Agent AI"란 용어는 문맥에 따라 약간씩 의미가 달라질 수 있지만, 일반적으로는 자율적으로 특정 작업을 수행하도록 설계된 인공지능 시스템을 의미합니다. 쉽게 말해, 어떤 목적이나 목표를 달성하기 위해 스스로 판단하고 행동할 수 있는 인공지능입니다.

예를 들어 설명하자면:
Agent AI는 다음과 같은 요소들을 가질 수 있어요:
목표(Goal): 예를 들어, 사용자의 이메일을 자동으로 정리해주는 것이 목표일 수 있어요.
환경 인식(Perception): 현재 어떤 이메일이 왔는지를 인식해야겠죠.
행동(Action): 중요 메일은 '중요' 폴더로 옮기고, 스팸은 지우는 식으로 행동합니다.
자율성(Autonomy): 사람의 명령 없이도 혼자서 작동할 수 있어요.

대표적인 예:
OpenAI의 AutoGPT, AgentGPT: 사용자가 "나를 위한 여행 계획 세워줘"라고 하면, 여러 단계를 스스로 계획하고 실행하는 Agent AI입니다.

RPA (Robotic Process Automation) + AI: 회사 업무 자동화에 Agent AI를 붙이면, 단순한 반복 작업뿐 아니라 판단까지 자동으로 수행할 수 있어요.

어디에 쓰일 수 있나요?
고객 서비스 챗봇
주식 매매 자동화
이메일 및 문서 자동 정리
사이버 보안 위협 탐지 및 대응
게임 캐릭터의 AI 행동 설계 등


💡 What is an LLM?
LLM stands for Large Language Model.
It’s a type of AI model trained on massive amounts of text data to understand and generate human-like language.

✅ Examples of LLMs:
ChatGPT (by OpenAI)
Claude (Anthropic)
Gemini (Google)
LLaMA (Meta)
Mistral, Command R, etc.

## Reasoning in Agent AI

Reasoning refers to the ability of an Agent AI to make decisions or solve problems based on the information it perceives from its environment. This involves logical thinking, pattern recognition, and decision-making processes that allow the AI to act autonomously.

### Key Aspects of Reasoning:
1. **Logical Deduction**: Drawing conclusions from known facts or rules.
   - Example: If an email is marked as "spam," move it to the spam folder.
   
2. **Pattern Recognition**: Identifying trends or anomalies in data.
   - Example: Detecting unusual login attempts in cybersecurity.

3. **Decision-Making**: Choosing the best action to achieve a goal.
   - Example: Prioritizing important emails over less critical ones.

4. **Learning from Feedback**: Adapting decisions based on past outcomes.
   - Example: Improving email categorization accuracy over time.

Reasoning enables Agent AI to operate effectively in dynamic environments, making it a critical component of autonomy and intelligence.


✅ Why Auto-Regressive Models Work So Well
1. Natural Language is Sequential
Human language is inherently ordered — we understand context based on what came before.

Auto-regressive models mimic this natural flow, which helps them generate coherent, context-aware responses.

2. Great for Generation Tasks
Since they predict one word at a time, AR models are perfect for generating text — stories, summaries, code, emails, etc.

Each new word is chosen with awareness of all the words before it, allowing fluid and logical writing.

3. High-Quality Outputs via Transformer Architecture
When combined with Transformer architectures (like in GPT), AR models can:

Attend to long-range dependencies in text

Track complex logic and reasoning

Adapt to many domains: medical, legal, programming...

4. Supports Complex Reasoning
By building answers token by token, they can simulate chains of thought, such as:

"If A is true, then B must be true. Since B leads to C, then…"

This "token-by-token logic building" helps in tasks like:

Math

Programming

Step-by-step problem solving

5. Scales Well with Data and Model Size
As AR models get more data and parameters, their ability to learn patterns and generalize improves dramatically (as we’ve seen from GPT-2 → GPT-3 → GPT-4).

🤖 Contrast: Auto-Encoding Models (e.g., BERT)
BERT-like models use masked language modeling (fill in the blanks).

Great for understanding tasks (classification, QA), but not as good for generating long, coherent text.

Not naturally suited for tasks requiring sequential reasoning or planning.

TL;DR
🔥 Auto-regressive models are better for generation and reasoning
Because they:

Predict one token at a time in sequence (like humans speak/write)

Build up logic step-by-step

Scale well with data

Work naturally with Transformers

1. RAG  가져온 문서에 질문에 정답이 없을때? -> 재질문 재 답변. 
2. Corrective RAG 질문의 답이 저장소에 없을때? -> 다시보고 웹에서 검색. 

3. Text2SQL - ㅡmuti agent , reflection , tool use  LangGraph+Text2SQL
4. Text2Chart (text to image) - step task decomposer (planning)-> tooluse -> reflection -> retouch prompt.
5. Text2Code - ? 


Bedrock 에 있는 agent capablitiy  
Lang graph 로 use case 가능. 

Not first..
기존의 솔루션의 성능향상을 위해 사용하는것. 
어렵게 한다고해서 잘한다고 생각하지 않는다. 
간단하게. 
구분하지 말고 문제를 풀자. 
